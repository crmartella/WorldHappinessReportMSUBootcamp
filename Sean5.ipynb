{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae993e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install prophet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3999d2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Regional Indicator</th>\n",
       "      <th>Year</th>\n",
       "      <th>Life Ladder</th>\n",
       "      <th>Log GDP Per Capita</th>\n",
       "      <th>Social Support</th>\n",
       "      <th>Healthy Life Expectancy At Birth</th>\n",
       "      <th>Freedom To Make Life Choices</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Perceptions Of Corruption</th>\n",
       "      <th>Positive Affect</th>\n",
       "      <th>Negative Affect</th>\n",
       "      <th>Confidence In National Government</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>2008</td>\n",
       "      <td>3.723590</td>\n",
       "      <td>7.350416</td>\n",
       "      <td>0.450662</td>\n",
       "      <td>50.500000</td>\n",
       "      <td>0.718114</td>\n",
       "      <td>0.167652</td>\n",
       "      <td>0.881686</td>\n",
       "      <td>0.414297</td>\n",
       "      <td>0.258195</td>\n",
       "      <td>0.612072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>2009</td>\n",
       "      <td>4.401778</td>\n",
       "      <td>7.508646</td>\n",
       "      <td>0.552308</td>\n",
       "      <td>50.799999</td>\n",
       "      <td>0.678896</td>\n",
       "      <td>0.190809</td>\n",
       "      <td>0.850035</td>\n",
       "      <td>0.481421</td>\n",
       "      <td>0.237092</td>\n",
       "      <td>0.611545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>2010</td>\n",
       "      <td>4.758381</td>\n",
       "      <td>7.613900</td>\n",
       "      <td>0.539075</td>\n",
       "      <td>51.099998</td>\n",
       "      <td>0.600127</td>\n",
       "      <td>0.121316</td>\n",
       "      <td>0.706766</td>\n",
       "      <td>0.516907</td>\n",
       "      <td>0.275324</td>\n",
       "      <td>0.299357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>2011</td>\n",
       "      <td>3.831719</td>\n",
       "      <td>7.581259</td>\n",
       "      <td>0.521104</td>\n",
       "      <td>51.400002</td>\n",
       "      <td>0.495901</td>\n",
       "      <td>0.163571</td>\n",
       "      <td>0.731109</td>\n",
       "      <td>0.479835</td>\n",
       "      <td>0.267175</td>\n",
       "      <td>0.307386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>2012</td>\n",
       "      <td>3.782938</td>\n",
       "      <td>7.660506</td>\n",
       "      <td>0.520637</td>\n",
       "      <td>51.700001</td>\n",
       "      <td>0.530935</td>\n",
       "      <td>0.237588</td>\n",
       "      <td>0.775620</td>\n",
       "      <td>0.613513</td>\n",
       "      <td>0.267919</td>\n",
       "      <td>0.435440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country Name Regional Indicator  Year  Life Ladder  Log GDP Per Capita  \\\n",
       "0  Afghanistan         South Asia  2008     3.723590            7.350416   \n",
       "1  Afghanistan         South Asia  2009     4.401778            7.508646   \n",
       "2  Afghanistan         South Asia  2010     4.758381            7.613900   \n",
       "3  Afghanistan         South Asia  2011     3.831719            7.581259   \n",
       "4  Afghanistan         South Asia  2012     3.782938            7.660506   \n",
       "\n",
       "   Social Support  Healthy Life Expectancy At Birth  \\\n",
       "0        0.450662                         50.500000   \n",
       "1        0.552308                         50.799999   \n",
       "2        0.539075                         51.099998   \n",
       "3        0.521104                         51.400002   \n",
       "4        0.520637                         51.700001   \n",
       "\n",
       "   Freedom To Make Life Choices  Generosity  Perceptions Of Corruption  \\\n",
       "0                      0.718114    0.167652                   0.881686   \n",
       "1                      0.678896    0.190809                   0.850035   \n",
       "2                      0.600127    0.121316                   0.706766   \n",
       "3                      0.495901    0.163571                   0.731109   \n",
       "4                      0.530935    0.237588                   0.775620   \n",
       "\n",
       "   Positive Affect  Negative Affect  Confidence In National Government  \n",
       "0         0.414297         0.258195                           0.612072  \n",
       "1         0.481421         0.237092                           0.611545  \n",
       "2         0.516907         0.275324                           0.299357  \n",
       "3         0.479835         0.267175                           0.307386  \n",
       "4         0.613513         0.267919                           0.435440  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happiness = pd.read_csv(\"Resources/World Happiness Report 2005 to 2023.csv\")\n",
    "happiness_total = pd.read_csv(\"Resources/World Happiness Report 2005 to 2023.csv\")\n",
    "happiness_ref = pd.read_csv(\"Resources/2019_global_happiness_reference.csv\")\n",
    "happiness.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5c12387",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2199 entries, 0 to 2198\n",
      "Data columns (total 13 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   Country Name                       2199 non-null   object \n",
      " 1   Regional Indicator                 2087 non-null   object \n",
      " 2   Year                               2199 non-null   int64  \n",
      " 3   Life Ladder                        2199 non-null   float64\n",
      " 4   Log GDP Per Capita                 2179 non-null   float64\n",
      " 5   Social Support                     2186 non-null   float64\n",
      " 6   Healthy Life Expectancy At Birth   2145 non-null   float64\n",
      " 7   Freedom To Make Life Choices       2166 non-null   float64\n",
      " 8   Generosity                         2126 non-null   float64\n",
      " 9   Perceptions Of Corruption          2083 non-null   float64\n",
      " 10  Positive Affect                    2175 non-null   float64\n",
      " 11  Negative Affect                    2183 non-null   float64\n",
      " 12  Confidence In National Government  1838 non-null   float64\n",
      "dtypes: float64(10), int64(1), object(2)\n",
      "memory usage: 223.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# happiness_total.info()\n",
    "happiness.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cd6123f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.4182866825779037\n",
      "R^2 Score: 0.6419698640863416\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values with mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose a Model (Linear Regression)\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the Model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the Model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25d64663",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Preprocess the Data\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m scaler \u001b[38;5;241m=\u001b[39m \u001b[43mStandardScaler\u001b[49m()\n\u001b[0;32m     10\u001b[0m X_train_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n\u001b[0;32m     11\u001b[0m X_test_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "# Define X and y based on the features and target variable in the 'happiness' dataset\n",
    "X = happiness[['Healthy Life Expectancy At Birth', 'Log GDP Per Capita', 'Freedom To Make Life Choices']]\n",
    "y = happiness['Life Ladder']\n",
    "\n",
    "# Split the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the Data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Select a Model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Train the Model\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate Performance\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Classification Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d713f786",
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bdf243",
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e357d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d90672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(happiness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec13bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "happiness_ref.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0a63a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_ref.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f11b022",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_plot = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f63245e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "happiness_total.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "236ee566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.4182866825779037\n",
      "R^2 Score: 0.6419698640863416\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values with mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose a Model (Linear Regression)\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the Model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the Model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4e7c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Best Model Parameters:\", grid_search.best_params_)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7f20a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Choose a Model (Linear Regression)\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the Model\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the Model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78efcc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Create PolynomialFeatures transformer\n",
    "poly_transformer = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "\n",
    "# Fit and transform the input features\n",
    "X_poly = poly_transformer.fit_transform(X)\n",
    "\n",
    "# Split the transformed data into training and testing sets\n",
    "X_train_poly, X_test_poly, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model on the transformed training data\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Evaluate the model on the transformed testing data\n",
    "y_pred = model.predict(X_test_poly)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29db17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Model (Linear Regression)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the Model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84208dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Select top k features\n",
    "selector = SelectKBest(score_func=f_regression, k=3)\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Model (Linear Regression)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the Model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c67cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Regression\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create polynomial features\n",
    "degree = 2  # Set the degree of the polynomial\n",
    "poly_features = PolynomialFeatures(degree=degree)\n",
    "X_poly_train = poly_features.fit_transform(X_train)\n",
    "X_poly_test = poly_features.transform(X_test)\n",
    "\n",
    "# Train Polynomial Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_poly_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e02057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Trees\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Train Decision Tree model\n",
    "model = DecisionTreeRegressor(max_depth=5)  # Set the maximum depth of the tree\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3938f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forests\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Train Random Forest model\n",
    "model = RandomForestRegressor(n_estimators=100, max_depth=5)  # Set the number of trees and maximum depth\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1c8cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Train Gradient Boosting model\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)  # Set the number of trees, learning rate, and maximum depth\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a16f2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Train Ridge Regression model\n",
    "alpha = 1.0  # Set the regularization strength (alpha)\n",
    "model = Ridge(alpha=alpha)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b184426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Train Lasso Regression model\n",
    "alpha = 1.0  # Set the regularization strength (alpha)\n",
    "model = Lasso(alpha=alpha)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df091e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Train Random Forest model\n",
    "model = RandomForestRegressor(n_estimators=100, max_depth=5)  # Set the number of trees and maximum depth\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f2ffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Train Gradient Boosting model\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)  # Set the number of trees, learning rate, and maximum depth\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea94c92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],  # Number of trees in the forest\n",
    "    'max_depth': [3, 5, 7],           # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4]     # Minimum number of samples required at each leaf node\n",
    "}\n",
    "\n",
    "# Create the Random Forest model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Instantiate the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172befcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning with Grid Search and Cross-Validation\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=GradientBoostingRegressor(), param_grid=param_grid, cv=5, scoring='r2')\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ed0001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define the model\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean Cross-Validation Score:\", np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8356373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Perform data augmentation by resampling\n",
    "# Let's assume 'X' and 'y' are your feature and target variables\n",
    "# 'X' should be a DataFrame containing your features, and 'y' should be a Series containing your target variable\n",
    "# We'll perform data augmentation by resampling the minority class (assuming binary classification)\n",
    "\n",
    "# Separate data by target class\n",
    "class_0 = happiness[happiness['target_column'] == 0]  # Assuming 'target_column' is your target variable\n",
    "class_1 = happiness[happiness['target_column'] == 1]\n",
    "\n",
    "# Upsample minority class ('class_1') to match the number of samples in the majority class ('class_0')\n",
    "class_1_augmented = resample(class_1, replace=True, n_samples=len(class_0), random_state=42)\n",
    "\n",
    "# Combine the original majority class ('class_0') with the upsampled minority class ('class_1_augmented')\n",
    "augmented_data = pd.concat([class_0, class_1_augmented])\n",
    "\n",
    "# Separate features and target variable\n",
    "X_augmented = augmented_data.drop('target_column', axis=1)  # Assuming 'target_column' is your target variable\n",
    "y_augmented = augmented_data['target_column']\n",
    "\n",
    "# Now you can use 'X_augmented' and 'y_augmented' as your augmented dataset for training your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f7ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Analysis\n",
    "\n",
    "# Obtain predictions from the trained model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute residuals\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# Analyze errors\n",
    "print(\"Mean Residual:\", np.mean(residuals))\n",
    "print(\"Median Residual:\", np.median(residuals))\n",
    "print(\"Standard Deviation of Residuals:\", np.std(residuals))\n",
    "\n",
    "# Visualize residuals\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(residuals, bins=20, kde=True)\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Residuals\")\n",
    "plt.show()\n",
    "\n",
    "# Investigate individual cases\n",
    "# For example, you can identify cases where the absolute residual is highest\n",
    "max_residual_idx = np.argmax(np.abs(residuals))\n",
    "max_residual_case = X_test.iloc[max_residual_idx]\n",
    "print(\"Max Residual Case Features:\")\n",
    "print(max_residual_case)\n",
    "print(\"Actual Value:\", y_test.iloc[max_residual_idx])\n",
    "print(\"Predicted Value:\", y_pred[max_residual_idx])\n",
    "print(\"Residual:\", residuals[max_residual_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5fadec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimentation and Iteration\n",
    "\n",
    "# Define experiment settings\n",
    "models = [LinearRegression(), RandomForestRegressor(), GradientBoostingRegressor()]\n",
    "hyperparameters = {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7]}\n",
    "feature_eng_methods = [None, 'polynomial_features', 'feature_selection']\n",
    "preprocessing_techniques = [StandardScaler(), MinMaxScaler(), None]\n",
    "\n",
    "best_model = None\n",
    "best_score = float('-inf')\n",
    "\n",
    "# Experiment loop\n",
    "for model in models:\n",
    "    for hp in hyperparameters:\n",
    "        for fe_method in feature_eng_methods:\n",
    "            for preprocessing in preprocessing_techniques:\n",
    "                # Preprocess data if necessary\n",
    "                if preprocessing:\n",
    "                    X_train_processed = preprocessing.fit_transform(X_train)\n",
    "                    X_test_processed = preprocessing.transform(X_test)\n",
    "                else:\n",
    "                    X_train_processed, X_test_processed = X_train, X_test\n",
    "                \n",
    "                # Apply feature engineering if necessary\n",
    "                if fe_method == 'polynomial_features':\n",
    "                    poly_features = PolynomialFeatures(degree=2)\n",
    "                    X_train_processed = poly_features.fit_transform(X_train_processed)\n",
    "                    X_test_processed = poly_features.transform(X_test_processed)\n",
    "                elif fe_method == 'feature_selection':\n",
    "                    # Apply feature selection technique\n",
    "                    pass  # Implement feature selection code here if applicable\n",
    "                \n",
    "                # Train and evaluate model\n",
    "                model.fit(X_train_processed, y_train)\n",
    "                y_pred = model.predict(X_test_processed)\n",
    "                score = r2_score(y_test, y_pred)\n",
    "                \n",
    "                # Update best model if current configuration performs better\n",
    "                if score > best_score:\n",
    "                    best_model = model\n",
    "                    best_score = score\n",
    "                    best_config = {'model': model, 'hyperparameters': hp, 'feature_eng_method': fe_method, 'preprocessing': preprocessing}\n",
    "\n",
    "# Print best configuration and score\n",
    "print(\"Best Configuration:\", best_config)\n",
    "print(\"Best R^2 Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445418c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "\n",
    "# 1. Split the Data (assuming X and y are your features and target variable)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Preprocess the Data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 3. Select a Model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# 4. Train the Model\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 5. Evaluate Performance\n",
    "# For classification accuracy\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Classification Accuracy:\", accuracy)\n",
    "\n",
    "# For R-squared score (if using a regression model)\n",
    "# y_pred = model.predict(X_test)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "# print(\"R-squared Score:\", r2)\n",
    "\n",
    "# 6. Hyperparameter Tuning (optional)\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
    "# grid_search.fit(X_train_scaled, y_train)\n",
    "# best_model = grid_search.best_estimator_\n",
    "# best_accuracy = grid_search.best_score_\n",
    "# print(\"Best Model:\", best_model)\n",
    "# print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb54fa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data (scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate performance\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Classification Accuracy:\", accuracy)\n",
    "\n",
    "# Plot actual vs. predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'k--', lw=2)\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual vs. Predicted Values\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15b1ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data (scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate performance\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Classification Accuracy:\", accuracy)\n",
    "\n",
    "# Create a DataFrame for actual vs. predicted values\n",
    "df_results = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "\n",
    "# Plot actual vs. predicted values using pandas\n",
    "df_results.plot(kind='scatter', x='Actual', y='Predicted', figsize=(10, 6))\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'k--', lw=2)\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual vs. Predicted Values\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84726336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing time series data with columns 'ds' (datetime) and 'y' (values)\n",
    "# Split the data into training and testing sets\n",
    "train_df = df[df['ds'] < '2022-01-01']\n",
    "test_df = df[df['ds'] >= '2022-01-01']\n",
    "\n",
    "# Initialize and fit Prophet model\n",
    "model = Prophet()\n",
    "model.fit(train_df)\n",
    "\n",
    "# Make forecasts\n",
    "future = model.make_future_dataframe(periods=len(test_df))  # Forecast length same as testing set\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# Evaluate performance\n",
    "# For example, you can calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(test_df['y'], forecast['yhat'])\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0360fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing time series data with columns 'date' and 'value'\n",
    "# Prepare Time Series Data\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(len(df) * 0.8)\n",
    "train_data, test_data = df[:train_size], df[train_size:]\n",
    "\n",
    "# Choose a Model (SARIMA)\n",
    "order = (1, 1, 1)  # ARIMA parameters\n",
    "seasonal_order = (1, 1, 1, 12)  # Seasonal parameters\n",
    "\n",
    "# Train the Model\n",
    "model = SARIMAX(train_data, order=order, seasonal_order=seasonal_order)\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Make Forecasts\n",
    "forecast = model_fit.forecast(steps=len(test_data))\n",
    "\n",
    "# Evaluate Performance\n",
    "mse = mean_squared_error(test_data, forecast)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_data.index, train_data, label='Training Data')\n",
    "plt.plot(test_data.index, test_data, label='Test Data')\n",
    "plt.plot(test_data.index, forecast, label='Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Time Series Forecasting with SARIMA')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c7bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have data stored in lists or arrays: x_values, y_values\n",
    "plt.plot(x_values, y_values)\n",
    "plt.xlabel('X Label')\n",
    "plt.ylabel('Y Label')\n",
    "plt.title('Title')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0cd3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have data stored in lists or arrays: categories, values\n",
    "plt.bar(categories, values)\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Title')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels if needed\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d25babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have data stored in a list or array: data\n",
    "plt.hist(data, bins=10, edgecolor='black')\n",
    "plt.xlabel('Bins')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a29e40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have data stored in lists or arrays: x_values, y_values\n",
    "plt.scatter(x_values, y_values)\n",
    "plt.xlabel('X Label')\n",
    "plt.ylabel('Y Label')\n",
    "plt.title('Title')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33733ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Assuming you have data stored in a DataFrame: df\n",
    "sns.boxplot(x='column_name', y='column_name', data=df)\n",
    "plt.xlabel('X Label')\n",
    "plt.ylabel('Y Label')\n",
    "plt.title('Title')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d3082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Assuming you have data stored in a DataFrame: df\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8f418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing predictor variables\n",
    "# Add a constant term to the predictor variables matrix\n",
    "X = add_constant(df)\n",
    "\n",
    "# Calculate VIF\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Variable\"] = X.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cb5e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sort the DataFrame by VIF values in descending order\n",
    "vif_sorted = vif.sort_values(by='VIF', ascending=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(vif_sorted['Variable'], vif_sorted['VIF'], color='skyblue')\n",
    "plt.xlabel('VIF')\n",
    "plt.ylabel('Variable')\n",
    "plt.title('VIF Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e43b446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
