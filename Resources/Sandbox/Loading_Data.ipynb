{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9021f9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c3fe697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    dataframe = Resources(2015, 2023)\n",
    "    dataframe.describe()\n",
    "\n",
    "    for column in dataframe.columns:\n",
    "        # graph all columns with numberic / continuous variables\n",
    "        if column != \"Region\":\n",
    "            plt.title(column)\n",
    "            plt.hist(dataframe[column], bins = 20)\n",
    "            plt.show()\n",
    "    \n",
    "    print(dataframe[\"Region\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd9bce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Resources(starting_year, ending_year):\n",
    "    \"\"\"Process the loading in of the data to store in a Pandas DataFrame\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The DataFrame storing the happiness data of over 150\n",
    "                          countries over several years\n",
    "    \"\"\"\n",
    "    regions, columns, rename = get_standard_information()\n",
    "    dataframe = read_files(starting_year, ending_year, rename, regions, columns)\n",
    "    \n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5f10920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standard_information():\n",
    "    \"\"\"Sets the desired column names in order to process and standardize the data\n",
    "\n",
    "    Returns:\n",
    "        list: The regions of each country in the dataset\n",
    "        list: The column names from the datasets to be kept\n",
    "        list: The names to be used for non-standard data\n",
    "    \"\"\"\n",
    "    dataframe_ref = pd.read_csv(\"Resources/2015.csv\")\n",
    "\n",
    "    # getting the region in order to add it to other datasets and correcting the\n",
    "    # errors\n",
    "    regions = dict(zip(dataframe_ref[\"Country\"], dataframe_ref[\"Region\"]))\n",
    "    regions[\"Namibia\"] = \"Sub-Saharan Africa\"\n",
    "    regions[\"Northern Cyprus\"] = regions[\"Cyprus\"]\n",
    "    regions[\"South Sudan\"] = \"Sub-Saharan Africa\"\n",
    "    regions[\"Somalia\"] = \"Sub-Saharan Africa\"\n",
    "    regions[\"Trinidad & Tobago\"] = \"Latin America and Caribbean\"\n",
    "    regions[\"Gambia\"] = \"Sub-Saharan Africa\"\n",
    "    regions[\"North Macedonia\"] = regions[\"Albania\"]\n",
    "    regions[\"Belize\"] = \"Latin America and Caribbean\"\n",
    "    regions[\"Taiwan Province of China\"] = \"Eastern Asia\"\n",
    "    regions[\"Hong Kong S.A.R., China\"] = \"Eastern Asia\"\n",
    "\n",
    "    columns = [\"Country\", \"Year\", \"Region\", \"Happiness Score\",\n",
    "               \"Economy (GDP per Capita)\", \"Health (Life Expectancy)\",\n",
    "               \"Freedom\", \"Trust (Government Corruption)\", \"Generosity\"]\n",
    "\n",
    "    rename = {\"Happiness.Score\": \"Happiness Score\",\n",
    "              \"Economy..GDP.per.Capita.\": \"Economy (GDP per Capita)\",\n",
    "              \"Health..Life.Expectancy.\": \"Health (Life Expectancy)\",\n",
    "              \"Trust..Government.Corruption.\": \"Trust (Government Corruption)\",\n",
    "              \"Score\": \"Happiness Score\",\n",
    "              \"GDP per capita\": \"Economy (GDP per Capita)\",\n",
    "              \"Social support\": \"Family\",\n",
    "              \"Healthy life expectancy\": \"Health (Life Expectancy)\",\n",
    "              \"Freedom to make life choices\": \"Freedom\",\n",
    "              \"Perceptions of corruption\": \"Trust (Government Corruption)\",\n",
    "              \"Regional indicator\": \"Region\"\n",
    "             }\n",
    "\n",
    "    return regions, columns, rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c08acaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(starting_year, ending_year, renamed, regions, columns):\n",
    "    \"\"\"Reads in the data from all of the CSV files\n",
    "\n",
    "    Args:\n",
    "        starting_year (int): The first year that the data is coming from\n",
    "        ending_year (int): The last year that the data is coming from\n",
    "        renamed (list): The names to be used for non-standard data\n",
    "        regions (list): The regions of each country in the dataset\n",
    "        columns (list): The column names from the datasets to be kept\n",
    "\n",
    "    Returns:\n",
    "        pandas.dataframe: All data from each of the years from all of the\n",
    "                          columns wanted\n",
    "    \"\"\"\n",
    "    dataframes = []\n",
    "\n",
    "    for year in range(starting_year, ending_year + 1):\n",
    "        file_name = \"data/\" + str(year) + \".csv\"\n",
    "        dataframe = pd.read_csv(file_name).rename(columns = renamed)\n",
    "        \n",
    "        # making sure that country and region is in every year's dataset\n",
    "        if \"Country or region\" in dataframe.columns:\n",
    "            dataframe.rename(columns = {\"Country or region\": \"Country\"},\\\n",
    "                inplace = True)\n",
    "        \n",
    "        if \"Region\" not in dataframe.columns:\n",
    "            # adding each country's region to all post-2015 data\n",
    "            dataframe[\"Region\"] = dataframe[\"Country\"].map(regions)\n",
    "        \n",
    "        # making note of the year in the data for reference in aggregated data\n",
    "        dataframe[\"Year\"] = year\n",
    "\n",
    "        # temporary fix for filling in the missing Trust (Government Corruption)\n",
    "        # value for the United Arab Emirates in 2018 with a 0 and assumes that\n",
    "        # any future dataset added will be a feature value (not a region,\n",
    "        # country name, or happiness score)\n",
    "        dataframe = dataframe.fillna(0)\n",
    "\n",
    "        if np.sum(dataframe.isna()).sum() > 0:\n",
    "            # last check before filling in the dataframe's missing values with\n",
    "            # 0 to the list to check where future datasets added may have any\n",
    "            # missing values\n",
    "            print(np.sum(dataframe.isna()))\n",
    "\n",
    "        dataframes.append(dataframe[columns])\n",
    "\n",
    "    # putting each year's data together\n",
    "    dataframe = pd.concat(dataframes)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a12bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dataframe, column_names):\n",
    "    \"\"\"\n",
    "    Splits the data into train data, train labels, test data, and test\n",
    "    labels\n",
    "\n",
    "    Args:\n",
    "        dataframe (pandas.dataframe): All data from each of the years from\n",
    "                                        all of the columns wanted\n",
    "        column_names (list): All the column names in dataframe to be saved\n",
    "\n",
    "    Returns:\n",
    "        NumPy.ndarray: labels\n",
    "        NumPy.ndarray: data\n",
    "    \"\"\"\n",
    "    # convert to a NumPy array in order to split the data into labels and\n",
    "    # data and into train and test data, specifically to work with the\n",
    "    # happiness dataset\n",
    "    data_numpy = dataframe[column_names].to_numpy()\n",
    "    data_column_indices = list(range(4, (len(column_names))))\n",
    "    labels = data_numpy[:, [0, 1, 2, 3]]\n",
    "    data = data_numpy[:, data_column_indices]\n",
    "    return labels, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "912fa07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data, labels, seed):\n",
    "    \"\"\"Splits the data and labels into train and test data\n",
    "\n",
    "    Args:\n",
    "        data (numpy.ndarray): The feature values of the dataset\n",
    "        labels (numpy.ndarray): The labels of each data (the happiness score)\n",
    "        seed (int): The specified seed to look at (or None to use the default\n",
    "                    seed)\n",
    "\n",
    "    Returns:\n",
    "        list: The data / feature values of the train data\n",
    "        list: The data / feature values of the test data\n",
    "        list: The labels of the train data\n",
    "        list: The labels of the test data\n",
    "    \"\"\"\n",
    "    if seed == None:\n",
    "        data_train, data_test, labels_train, labels_test =\\\n",
    "            train_test_split(data, labels, test_size = 0.20)\n",
    "        return data_train, data_test, labels_train, labels_test\n",
    "    \n",
    "    data_train, data_test, labels_train, labels_test =\\\n",
    "        train_test_split(data, labels, test_size = 0.20,\\\n",
    "            random_state = seed)\n",
    "    return data_train, data_test, labels_train, labels_test\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450743ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021b2cda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8f9a99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
